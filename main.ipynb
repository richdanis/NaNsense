{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "h0EPX9TBwTq6",
   "metadata": {
    "id": "h0EPX9TBwTq6"
   },
   "source": [
    "## **üõ†Ô∏è Tools You May Consider**  \n",
    "(*These are recommendations to help you get started. You are free to use alternative tools‚Äîjust document your choices clearly!*)  \n",
    "- **Database**: FAISS, ChromaDB, SQLite, Elasticsearch, Neo4j and etc.  \n",
    "- **Embedding Models**: Hugging Face Sentence-Transformers, OpenAI Embeddings  \n",
    "- **LLM for Generation**: OpenAI: gpt-4o-mini\n",
    "- **Others**: Langchain, GraphRAG, and etc.\n",
    "\n",
    "## **üìå Final Delivery**  \n",
    "Your final submission should include:  \n",
    "‚úÖ A well-documented **GitHub repository or notebook**  \n",
    "‚úÖ A clear **README** explaining your approach  \n",
    "‚úÖ A structured **retrieval and generation modules**  \n",
    "\n",
    "### **üî• Bonus Points For**  \n",
    "‚ú® Innovative retrieval techniques  \n",
    "‚ú® Well-organized, modular code  \n",
    "‚ú® Creative visualizations or user interfaces  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ipz5In6W_NIx",
   "metadata": {
    "id": "Ipz5In6W_NIx"
   },
   "source": [
    "# 1. Set up working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dkuJ8NdPn8pc",
   "metadata": {
    "id": "dkuJ8NdPn8pc"
   },
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "\n",
    "# # Database options\n",
    "# !pip install chromadb # if you use chromadb as your vector database\n",
    "\n",
    "# # Others\n",
    "# !pip install langchain-community # if you use langchain for orchastration\n",
    "# !pip install transformers #if you use huggingface for vector embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80UAVJcCkCM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a80UAVJcCkCM",
    "outputId": "cc853a6b-c9d9-4c61-f1bb-3f10705fe61f"
   },
   "outputs": [],
   "source": [
    "# enable GPU if needed, GPU can speed up your vector embedding if you computing these vectors locally (not using API)\n",
    "\n",
    "# import torch\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ed41c7",
   "metadata": {
    "id": "20ed41c7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import chromadb\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.chains import RetrievalQA\n",
    "\n",
    "# # Set OpenAI API Key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EQPuHKS4QQjn",
   "metadata": {
    "id": "EQPuHKS4QQjn"
   },
   "source": [
    "# 2. Knowledge Base Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C1ZmEq85_XvG",
   "metadata": {
    "id": "C1ZmEq85_XvG"
   },
   "source": [
    "## 2.1 Load documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2GpLOcX8xoQ1",
   "metadata": {
    "id": "2GpLOcX8xoQ1"
   },
   "source": [
    "Once you are added access to this folder, it will appear at your google drive \"Shared drives\". Then you can mount your drive and as following, and access your data from \"/content/drive/Shared drives/Datathon/Data/hackathon_data/\". Enjoy the ride! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kUvCnCVnRf5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUvCnCVnRf5c",
    "outputId": "f920db58-f4b9-4813-c0e5-8f8520c7a7cc"
   },
   "outputs": [],
   "source": [
    "# Load the Drive and mount\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jQt4yk-y_LqU",
   "metadata": {
    "id": "jQt4yk-y_LqU"
   },
   "source": [
    "Load json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7rVVlmZ3KMTJ",
   "metadata": {
    "id": "7rVVlmZ3KMTJ"
   },
   "outputs": [],
   "source": [
    "# folder_path = \"/content/drive/Shared drives/Datathon/Data/hackathon_data/\"# Google drive path of the dataset\n",
    "folder_path = \"../data/hackathon_data/\"\n",
    "files_in_folder = os.listdir(folder_path)\n",
    "\n",
    "len(files_in_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AdSRf4xB_KWM",
   "metadata": {
    "id": "AdSRf4xB_KWM"
   },
   "outputs": [],
   "source": [
    "def load_documents(json_file):\n",
    "    \"\"\"Loads the JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "      try:\n",
    "          data = json.load(f)\n",
    "          return data\n",
    "      except json.JSONDecodeError:\n",
    "          print(f\"Error reading {json_file}, it may not be a valid JSON file.\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PXf9s94Axg8U",
   "metadata": {
    "id": "PXf9s94Axg8U"
   },
   "outputs": [],
   "source": [
    "for filename in files_in_folder:\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        doc = load_documents(file_path)\n",
    "        break\n",
    "print(doc.keys())\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LTUgoion_dLj",
   "metadata": {
    "id": "LTUgoion_dLj"
   },
   "source": [
    "## 2.2 Pre-process documents.\n",
    "\n",
    "Feel free to explore and pre-process the data. You may want to clean or segment the documents as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yI1cBtnDyOx0",
   "metadata": {
    "id": "yI1cBtnDyOx0"
   },
   "outputs": [],
   "source": [
    "def page_segment(docs):\n",
    "    \"\"\"You may prefer to load each page separately.\"\"\"\n",
    "    i = 0\n",
    "    page_segment = []\n",
    "    for s in list(docs['text_by_page_url'].values()):\n",
    "      page_segment.append({\"docID\": docs['doc_id'], \"pageID\": 'page_' + str(i), \"text\": s})\n",
    "      i += 1\n",
    "    return page_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sjl7Xp1Pw6ps",
   "metadata": {
    "id": "Sjl7Xp1Pw6ps"
   },
   "outputs": [],
   "source": [
    "def segment_documents(docs, chunk_size=500):\n",
    "    \"\"\"Segments documents into chunks of a given token size. Replace this function with your segmentation approach or maybe use the original document without segmentation.\"\"\"\n",
    "    segmented = []\n",
    "    for doc_id, content in docs.items():\n",
    "        for i in range(0, len(content), chunk_size):\n",
    "            segment = content[i : i + chunk_size]\n",
    "            segmented.append({\"id\": doc_id, \"text\": segment})\n",
    "    return segmented\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x_3mbRONy7M7",
   "metadata": {
    "id": "x_3mbRONy7M7"
   },
   "outputs": [],
   "source": [
    "def document_clean(docs):\n",
    "  \"\"\"\n",
    "  You may want to clean the dataset, add the code here.\n",
    "  \"\"\"\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qrhr__MeK-hY",
   "metadata": {
    "id": "qrhr__MeK-hY"
   },
   "source": [
    "## 2.3 Document Indexing and Storage (Profiling)\n",
    "\n",
    "Feel free to choose different ways to indexing and storing the provided documents in a knowledge database.\n",
    "\n",
    "So that they can be retrieved in different ways according to your system design choices, such as search by keywords, vector representation, graph relation, and etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "woyxfDBeN_mG",
   "metadata": {
    "id": "woyxfDBeN_mG"
   },
   "source": [
    "# 3. Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hSBIL9B-k1wE",
   "metadata": {
    "id": "hSBIL9B-k1wE"
   },
   "source": [
    "## 3.1 Load Knowledge Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7LOy1k_-lOu0",
   "metadata": {
    "id": "7LOy1k_-lOu0"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "X6jZ743wLayQ",
   "metadata": {
    "id": "X6jZ743wLayQ"
   },
   "source": [
    "## 3.2 Relevant Document Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xj5pH-FATv6S",
   "metadata": {
    "id": "xj5pH-FATv6S"
   },
   "source": [
    "Feel free to check and improve your retrieval performance as it affect the generation results significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a647547",
   "metadata": {
    "id": "6a647547"
   },
   "outputs": [],
   "source": [
    "def retrieve_documents(query, db_path, embedding_model):\n",
    "  \"\"\"\n",
    "  retrieve relevant documents from the knowledge database to the query.\n",
    "  \"\"\"\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kYJCpsgHLoc-",
   "metadata": {
    "id": "kYJCpsgHLoc-"
   },
   "source": [
    "## 3.3 Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "-6xIzmDTn3I8",
   "metadata": {
    "id": "-6xIzmDTn3I8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What company is located in 29010 Commerce Center Dr., Valencia, 91355, California, US?\n",
      "Retrieved Documents: ['ABC Corporation is located at 29010 Commerce Center Dr., Valencia, 91355, California, US.']\n",
      "Generated Answer: I don't have enough information to answer this question.\n"
     ]
    }
   ],
   "source": [
    "from src.prompts import generate_answer, load_prompts\n",
    "\n",
    "query = \"What company is located in 29010 Commerce Center Dr., Valencia, 91355, California, US?\"\n",
    "retrieved_docs = [\"ABC Corporation is located at 29010 Commerce Center Dr., Valencia, 91355, California, US.\"]\n",
    "prompts = load_prompts()\n",
    "prompt_template = prompts[\"rag_default\"]\n",
    "response = generate_answer(query, retrieved_texts=\"Lalo\", prompt_template=prompt_template, model=\"gpt-4o\")\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Retrieved Documents:\", [\"ABC Corporation is located at 29010 Commerce Center Dr., Valencia, 91355, California, US.\"])\n",
    "print(\"Generated Answer:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RK8CQELywSf1",
   "metadata": {
    "id": "RK8CQELywSf1"
   },
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd94a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
